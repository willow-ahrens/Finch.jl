<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Optimization Tips · Finch.jl</title><meta name="title" content="Optimization Tips · Finch.jl"/><meta property="og:title" content="Optimization Tips · Finch.jl"/><meta property="twitter:title" content="Optimization Tips · Finch.jl"/><meta name="description" content="Documentation for Finch.jl."/><meta property="og:description" content="Documentation for Finch.jl."/><meta property="twitter:description" content="Documentation for Finch.jl."/><meta property="og:url" content="https://willow-ahrens.github.io/Finch.jl/guides/optimization_tips/"/><meta property="twitter:url" content="https://willow-ahrens.github.io/Finch.jl/guides/optimization_tips/"/><link rel="canonical" href="https://willow-ahrens.github.io/Finch.jl/guides/optimization_tips/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="Finch.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Finch.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Comprehensive Guides</span><ul><li><a class="tocitem" href="../calling_finch/">Calling Finch</a></li><li><a class="tocitem" href="../tensor_formats/">Tensor Formats</a></li><li><a class="tocitem" href="../sparse_utils/">Sparse and Structured Utilities</a></li><li><a class="tocitem" href="../finch_language/">The Finch Language</a></li><li><a class="tocitem" href="../dimensionalization/">Dimensionalization</a></li><li><a class="tocitem" href="../index_sugar/">Index Sugar</a></li><li><a class="tocitem" href="../mask_sugar/">Mask Sugar</a></li><li><a class="tocitem" href="../iteration_protocols/">Iteration Protocols</a></li><li><a class="tocitem" href="../custom_operators/">Custom Operators</a></li><li><a class="tocitem" href="../array_api/">High-Level Array API</a></li><li><a class="tocitem" href="../fileio/">FileIO</a></li><li><a class="tocitem" href="../interoperability/">Interoperability</a></li><li class="is-active"><a class="tocitem" href>Optimization Tips</a><ul class="internal"><li><a class="tocitem" href="#Concordant-Iteration"><span>Concordant Iteration</span></a></li><li><a class="tocitem" href="#Appropriate-Fill-Values"><span>Appropriate Fill Values</span></a></li><li><a class="tocitem" href="#Static-Versus-Dynamic-Values"><span>Static Versus Dynamic Values</span></a></li><li><a class="tocitem" href="#Use-Known-Functions"><span>Use Known Functions</span></a></li><li><a class="tocitem" href="#Type-Stability"><span>Type Stability</span></a></li></ul></li><li><a class="tocitem" href="../benchmarking_tips/">Benchmarking Tips</a></li></ul></li><li><span class="tocitem">Technical Reference</span><ul><li><a class="tocitem" href="../../reference/listing/">Documentation Listing</a></li><li><input class="collapse-toggle" id="menuitem-3-2" type="checkbox"/><label class="tocitem" for="menuitem-3-2"><span class="docs-label">Advanced Implementation Details</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../reference/advanced_implementation/internals/">Internals</a></li><li><a class="tocitem" href="../../reference/advanced_implementation/tensor_interface/">Tensor Interface</a></li></ul></li></ul></li><li><a class="tocitem" href="../../CONTRIBUTING/">Community and Contributions</a></li><li><span class="tocitem">Appendices and Additional Resources</span><ul><li><a class="tocitem" href="../../appendices/directory_structure/">Directory Structure</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Comprehensive Guides</a></li><li class="is-active"><a href>Optimization Tips</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Optimization Tips</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/willow-ahrens/Finch.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/willow-ahrens/Finch.jl/blob/main/docs/src/guides/optimization_tips.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Optimization-Tips-for-Finch"><a class="docs-heading-anchor" href="#Optimization-Tips-for-Finch">Optimization Tips for Finch</a><a id="Optimization-Tips-for-Finch-1"></a><a class="docs-heading-anchor-permalink" href="#Optimization-Tips-for-Finch" title="Permalink"></a></h1><p>It&#39;s easy to ask Finch to run the same operation in different ways. However, different approaches have different performance. The right approach really depends on your particular situation. Here&#39;s a collection of general approaches that help Finch generate faster code in most cases.</p><h2 id="Concordant-Iteration"><a class="docs-heading-anchor" href="#Concordant-Iteration">Concordant Iteration</a><a id="Concordant-Iteration-1"></a><a class="docs-heading-anchor-permalink" href="#Concordant-Iteration" title="Permalink"></a></h2><p>By default, Finch stores arrays in column major order (first index fast). When the storage order of an array in a Finch expression corresponds to the loop order, we call this <em>concordant</em> iteration. For example, the following expression represents a concordant traversal of a sparse matrix, as the outer loops access the higher levels of the tensor tree:</p><pre><code class="language-julia hljs">A = Tensor(Dense(SparseList(Element(0.0))), fsparse([2, 3, 4, 1, 3], [1, 1, 1, 3, 3], [1.1, 2.2, 3.3, 4.4, 5.5], (4, 3)))
s = Scalar(0.0)
@finch for j=_, i=_ ; s[] += A[i, j] end

# output

NamedTuple()</code></pre><p>We can investigate the generated code with <code>@finch_code</code>.  This code iterates over only the nonzeros in order. If our matrix is <code>m × n</code> with <code>nnz</code> nonzeros, this takes <code>O(n + nnz)</code> time.</p><pre><code class="language-julia hljs">@finch_code for j=_, i=_ ; s[] += A[i, j] end

# output

quote
    s = (ex.bodies[1]).body.body.lhs.tns.bind
    s_val = s.val
    A_lvl = (ex.bodies[1]).body.body.rhs.tns.bind.lvl
    A_lvl_2 = A_lvl.lvl
    A_lvl_ptr = A_lvl_2.ptr
    A_lvl_idx = A_lvl_2.idx
    A_lvl_2_val = A_lvl_2.lvl.val
    result = nothing
    for j_3 = 1:A_lvl.shape
        A_lvl_q = (1 - 1) * A_lvl.shape + j_3
        A_lvl_2_q = A_lvl_ptr[A_lvl_q]
        A_lvl_2_q_stop = A_lvl_ptr[A_lvl_q + 1]
        if A_lvl_2_q &lt; A_lvl_2_q_stop
            A_lvl_2_i1 = A_lvl_idx[A_lvl_2_q_stop - 1]
        else
            A_lvl_2_i1 = 0
        end
        phase_stop = min(A_lvl_2_i1, A_lvl_2.shape)
        if phase_stop &gt;= 1
            if A_lvl_idx[A_lvl_2_q] &lt; 1
                A_lvl_2_q = Finch.scansearch(A_lvl_idx, 1, A_lvl_2_q, A_lvl_2_q_stop - 1)
            end
            while true
                A_lvl_2_i = A_lvl_idx[A_lvl_2_q]
                if A_lvl_2_i &lt; phase_stop
                    A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                    s_val = A_lvl_3_val + s_val
                    A_lvl_2_q += 1
                else
                    phase_stop_3 = min(A_lvl_2_i, phase_stop)
                    if A_lvl_2_i == phase_stop_3
                        A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                        s_val += A_lvl_3_val
                        A_lvl_2_q += 1
                    end
                    break
                end
            end
        end
    end
    result = ()
    s.val = s_val
    result
end</code></pre><p>When the loop order does not correspond to storage order, we call this <em>discordant</em> iteration. For example, if we swap the loop order in the above example, then Finch needs to randomly access each sparse column for each row <code>i</code>. We end up needing to find each <code>(i, j)</code> pair because we don&#39;t know whether it will be zero until we search for it. In all, this takes time <code>O(n * m * log(nnz))</code>, much less efficient! We shouldn&#39;t randomly access sparse arrays unless we really need to and they support it efficiently!</p><p>Note the double for loop in the following code</p><pre><code class="language-julia hljs">@finch_code for i=_, j=_ ; s[] += A[i, j] end # DISCORDANT, DO NOT DO THIS

# output

quote
    s = (ex.bodies[1]).body.body.lhs.tns.bind
    s_val = s.val
    A_lvl = (ex.bodies[1]).body.body.rhs.tns.bind.lvl
    A_lvl_2 = A_lvl.lvl
    A_lvl_ptr = A_lvl_2.ptr
    A_lvl_idx = A_lvl_2.idx
    A_lvl_2_val = A_lvl_2.lvl.val
    @warn &quot;Performance Warning: non-concordant traversal of A[i, j] (hint: most arrays prefer column major or first index fast, run in fast mode to ignore this warning)&quot;
    result = nothing
    for i_3 = 1:A_lvl_2.shape
        for j_3 = 1:A_lvl.shape
            A_lvl_q = (1 - 1) * A_lvl.shape + j_3
            A_lvl_2_q = A_lvl_ptr[A_lvl_q]
            A_lvl_2_q_stop = A_lvl_ptr[A_lvl_q + 1]
            if A_lvl_2_q &lt; A_lvl_2_q_stop
                A_lvl_2_i1 = A_lvl_idx[A_lvl_2_q_stop - 1]
            else
                A_lvl_2_i1 = 0
            end
            phase_stop = min(i_3, A_lvl_2_i1)
            if phase_stop &gt;= i_3
                if A_lvl_idx[A_lvl_2_q] &lt; i_3
                    A_lvl_2_q = Finch.scansearch(A_lvl_idx, i_3, A_lvl_2_q, A_lvl_2_q_stop - 1)
                end
                while true
                    A_lvl_2_i = A_lvl_idx[A_lvl_2_q]
                    if A_lvl_2_i &lt; phase_stop
                        A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                        s_val = A_lvl_3_val + s_val
                        A_lvl_2_q += 1
                    else
                        phase_stop_3 = min(A_lvl_2_i, phase_stop)
                        if A_lvl_2_i == phase_stop_3
                            A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                            s_val += A_lvl_3_val
                            A_lvl_2_q += 1
                        end
                        break
                    end
                end
            end
        end
    end
    result = ()
    s.val = s_val
    result
end</code></pre><p>TL;DR: As a quick heuristic, if your array indices are all in alphabetical order, then the loop indices should be reverse alphabetical.</p><h2 id="Appropriate-Fill-Values"><a class="docs-heading-anchor" href="#Appropriate-Fill-Values">Appropriate Fill Values</a><a id="Appropriate-Fill-Values-1"></a><a class="docs-heading-anchor-permalink" href="#Appropriate-Fill-Values" title="Permalink"></a></h2><p>The @finch macro requires the user to specify an output format. This is the most flexibile approach, but can sometimes lead to densification unless the output fill value is appropriate for the computation.</p><p>For example, if <code>A</code> is <code>m × n</code> with <code>nnz</code> nonzeros, the following Finch kernel will densify <code>B</code>, filling it with <code>m * n</code> stored values:</p><pre><code class="language-julia hljs">A = Tensor(Dense(SparseList(Element(0.0))), fsparse([2, 3, 4, 1, 3], [1, 1, 1, 3, 3], [1.1, 2.2, 3.3, 4.4, 5.5], (4, 3)))
B = Tensor(Dense(SparseList(Element(0.0)))) #DO NOT DO THIS, B has the wrong fill value
@finch (B .= 0; for j=_, i=_; B[i, j] = A[i, j] + 1 end; return B)
countstored(B)

# output

12</code></pre><p>Since <code>A</code> is filled with <code>0.0</code>, adding <code>1</code> to the fill value produces <code>1.0</code>. However, <code>B</code> can only represent a fill value of <code>0.0</code>. Instead, we should specify <code>1.0</code> for the fill.</p><pre><code class="language-julia hljs">A = Tensor(Dense(SparseList(Element(0.0))), fsparse([2, 3, 4, 1, 3], [1, 1, 1, 3, 3], [1.1, 2.2, 3.3, 4.4, 5.5], (4, 3)))
B = Tensor(Dense(SparseList(Element(1.0))))
@finch (B .= 1; for j=_, i=_; B[i, j] = A[i, j] + 1 end; return B)
countstored(B)

# output

5</code></pre><h2 id="Static-Versus-Dynamic-Values"><a class="docs-heading-anchor" href="#Static-Versus-Dynamic-Values">Static Versus Dynamic Values</a><a id="Static-Versus-Dynamic-Values-1"></a><a class="docs-heading-anchor-permalink" href="#Static-Versus-Dynamic-Values" title="Permalink"></a></h2><p>In order to skip some computations, Finch must be able to determine the value of program variables. Continuing our above example, if we obscure the value of <code>1</code> behind a variable <code>x</code>, Finch can only determine that <code>x</code> has type <code>Int</code>, not that it is <code>1</code>.</p><pre><code class="language-julia hljs">A = Tensor(Dense(SparseList(Element(0.0))), fsparse([2, 3, 4, 1, 3], [1, 1, 1, 3, 3], [1.1, 2.2, 3.3, 4.4, 5.5], (4, 3)))
B = Tensor(Dense(SparseList(Element(1.0))))
x = 1 #DO NOT DO THIS, Finch cannot see the value of x anymore
@finch (B .= 1; for j=_, i=_; B[i, j] = A[i, j] + x end; return B)
countstored(B)

# output

12</code></pre><p>However, there are some situations where you may want a value to be dynamic. For example, consider the function <code>saxpy(x, a, y) = x .* a .+ y</code>. Because we do not know the value of <code>a</code> until we run the function, we should treat it as dynamic, and the following implementation is reasonable:</p><pre><code class="language-julia hljs">function saxpy(x, a, y)
    z = Tensor(SparseList(Element(0.0)))
    @finch (z .= 0; for i=_; z[i] = a * x[i] + y[i] end; return z)
end</code></pre><h2 id="Use-Known-Functions"><a class="docs-heading-anchor" href="#Use-Known-Functions">Use Known Functions</a><a id="Use-Known-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Use-Known-Functions" title="Permalink"></a></h2><p>Unless you declare the properties of your functions using Finch&#39;s <a href="../custom_operators/#Custom-Operators">Custom Operators</a> interface, Finch doesn&#39;t know how they work. For example, using a lambda obscures the meaning of <code>*</code>.</p><pre><code class="language-julia hljs">A = Tensor(Dense(SparseList(Element(0.0))), fsparse([2, 3, 4, 1, 3], [1, 1, 1, 3, 3], [1.1, 2.2, 3.3, 4.4, 5.5], (4, 3)))
B = ones(4, 3)
C = Scalar(0.0)
f(x, y) = x * y # DO NOT DO THIS, Obscures *
@finch (C .= 0; for j=_, i=_; C[] += f(A[i, j], B[i, j]) end; return C)

# output

(C = Scalar{0.0, Float64}(16.5),)</code></pre><p>Checking the generated code, we see that this code is indeed densifying (notice the for-loop which repeatedly evaluates <code>f(B[i, j], 0.0)</code>).</p><pre><code class="language-julia hljs">@finch_code (C .= 0; for j=_, i=_; C[] += f(A[i, j], B[i, j]) end; return C)

# output

quote
    C = ((ex.bodies[1]).bodies[1]).tns.bind
    A_lvl = (((ex.bodies[1]).bodies[2]).body.body.rhs.args[1]).tns.bind.lvl
    A_lvl_2 = A_lvl.lvl
    A_lvl_ptr = A_lvl_2.ptr
    A_lvl_idx = A_lvl_2.idx
    A_lvl_2_val = A_lvl_2.lvl.val
    B = (((ex.bodies[1]).bodies[2]).body.body.rhs.args[2]).tns.bind
    sugar_1 = size((((ex.bodies[1]).bodies[2]).body.body.rhs.args[2]).tns.bind)
    B_mode1_stop = sugar_1[1]
    B_mode2_stop = sugar_1[2]
    B_mode1_stop == A_lvl_2.shape || throw(DimensionMismatch(&quot;mismatched dimension limits ($(B_mode1_stop) != $(A_lvl_2.shape))&quot;))
    B_mode2_stop == A_lvl.shape || throw(DimensionMismatch(&quot;mismatched dimension limits ($(B_mode2_stop) != $(A_lvl.shape))&quot;))
    needs_return = true
    result = nothing
    C_val = 0
    for j_4 = 1:B_mode2_stop
        A_lvl_q = (1 - 1) * A_lvl.shape + j_4
        A_lvl_2_q = A_lvl_ptr[A_lvl_q]
        A_lvl_2_q_stop = A_lvl_ptr[A_lvl_q + 1]
        if A_lvl_2_q &lt; A_lvl_2_q_stop
            A_lvl_2_i1 = A_lvl_idx[A_lvl_2_q_stop - 1]
        else
            A_lvl_2_i1 = 0
        end
        phase_stop = min(B_mode1_stop, A_lvl_2_i1)
        if phase_stop &gt;= 1
            i = 1
            if A_lvl_idx[A_lvl_2_q] &lt; 1
                A_lvl_2_q = Finch.scansearch(A_lvl_idx, 1, A_lvl_2_q, A_lvl_2_q_stop - 1)
            end
            while true
                A_lvl_2_i = A_lvl_idx[A_lvl_2_q]
                if A_lvl_2_i &lt; phase_stop
                    for i_6 = i:-1 + A_lvl_2_i
                        val = B[i_6, j_4]
                        C_val = (Main).f(0.0, val) + C_val
                    end
                    A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                    val = B[A_lvl_2_i, j_4]
                    C_val += (Main).f(A_lvl_3_val, val)
                    A_lvl_2_q += 1
                    i = A_lvl_2_i + 1
                else
                    phase_stop_3 = min(A_lvl_2_i, phase_stop)
                    if A_lvl_2_i == phase_stop_3
                        for i_8 = i:-1 + phase_stop_3
                            val = B[i_8, j_4]
                            C_val += (Main).f(0.0, val)
                        end
                        A_lvl_3_val = A_lvl_2_val[A_lvl_2_q]
                        val = B[phase_stop_3, j_4]
                        C_val += (Main).f(A_lvl_3_val, val)
                        A_lvl_2_q += 1
                    else
                        for i_10 = i:phase_stop_3
                            val = B[i_10, j_4]
                            C_val += (Main).f(0.0, val)
                        end
                    end
                    i = phase_stop_3 + 1
                    break
                end
            end
        end
        phase_start_3 = max(1, 1 + A_lvl_2_i1)
        if B_mode1_stop &gt;= phase_start_3
            for i_12 = phase_start_3:B_mode1_stop
                val = B[i_12, j_4]
                C_val += (Main).f(0.0, val)
            end
        end
    end
    C.val = C_val
    result = (C = C,)
    needs_return = false
    if needs_return
        result = (C = C,)
    end
    result
end
</code></pre><h2 id="Type-Stability"><a class="docs-heading-anchor" href="#Type-Stability">Type Stability</a><a id="Type-Stability-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Stability" title="Permalink"></a></h2><p>Julia code runs fastest when the compiler can <a href="https://docs.julialang.org/en/v1/manual/performance-tips/#Write-%22type-stable%22-functions">infer the types</a> of all intermediate values.  Finch does not check that the generated code is type-stable. In situations where tensors have nonuniform index or element types, or the computation itself might involve multiple types, one should check that the output of <code>@finch_kernel</code> code is type-stable with <a href="https://docs.julialang.org/en/v1/stdlib/InteractiveUtils/#InteractiveUtils.@code_warntype"><code>@code_warntype</code></a>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../interoperability/">« Interoperability</a><a class="docs-footer-nextpage" href="../benchmarking_tips/">Benchmarking Tips »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 13 May 2024 17:57">Monday 13 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
